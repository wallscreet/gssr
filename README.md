# Goal-Conditioned State Space Reasoning

## AGI is hiding in latent space

I hypothesize that test-time adaptation of hybrid State Space Models (SSMs), such as those in the IBM Granite-4.0 series, can be effectively achieved through goal-conditioned perturbations applied to recurrent latent states during inference. This approach could enable dynamic steering of model outputs toward desired behaviors without updating model parameters, thereby demonstrating a lightweight form of test-time fine-tuning that preserves training stability while enhancing adaptability to specific tasks or domains.
